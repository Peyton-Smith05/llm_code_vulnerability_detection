{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba8c98c-60b7-4a11-a2a4-593ec83b530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ------------\n",
      "accelerate                0.23.0\n",
      "aiohttp                   3.8.5\n",
      "aiosignal                 1.3.1\n",
      "annotated-types           0.5.0\n",
      "anyio                     4.0.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.2.3\n",
      "asttokens                 2.4.0\n",
      "async-lru                 2.0.4\n",
      "async-timeout             4.0.3\n",
      "attrs                     23.1.0\n",
      "auto-gptq                 0.4.2\n",
      "Babel                     2.12.1\n",
      "backcall                  0.2.0\n",
      "backoff                   2.2.1\n",
      "beautifulsoup4            4.12.2\n",
      "bleach                    6.0.0\n",
      "certifi                   2023.7.22\n",
      "cffi                      1.15.1\n",
      "charset-normalizer        3.2.0\n",
      "clarifai                  9.8.1\n",
      "clarifai-grpc             9.8.2\n",
      "cmake                     3.27.4.1\n",
      "cohere                    4.26.1\n",
      "comm                      0.1.4\n",
      "dataclasses-json          0.5.14\n",
      "datasets                  2.14.5\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "dill                      0.3.7\n",
      "exceptiongroup            1.1.3\n",
      "executing                 1.2.0\n",
      "fastavro                  1.8.2\n",
      "fastjsonschema            2.18.0\n",
      "filelock                  3.12.4\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.4.0\n",
      "fsspec                    2023.6.0\n",
      "googleapis-common-protos  1.60.0\n",
      "greenlet                  2.0.2\n",
      "grpcio                    1.58.0\n",
      "huggingface-hub           0.17.1\n",
      "idna                      3.4\n",
      "importlib-metadata        6.8.0\n",
      "ipykernel                 6.25.2\n",
      "ipython                   8.15.0\n",
      "ipython-genutils          0.2.0\n",
      "ipywidgets                8.1.1\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.0\n",
      "Jinja2                    3.1.2\n",
      "json5                     0.9.14\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.19.0\n",
      "jsonschema-specifications 2023.7.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.3.1\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.3.1\n",
      "jupyter-events            0.7.0\n",
      "jupyter-lsp               2.2.0\n",
      "jupyter_server            2.7.3\n",
      "jupyter_server_terminals  0.4.4\n",
      "jupyterlab                4.0.6\n",
      "jupyterlab-pygments       0.2.2\n",
      "jupyterlab_server         2.25.0\n",
      "jupyterlab-widgets        3.0.9\n",
      "langchain                 0.0.292\n",
      "langsmith                 0.0.37\n",
      "lit                       16.0.6\n",
      "manifest-ml               0.0.1\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.3\n",
      "marshmallow               3.20.1\n",
      "matplotlib-inline         0.1.6\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.0.1\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.0.4\n",
      "multiprocess              0.70.15\n",
      "mypy-extensions           1.0.0\n",
      "nbclient                  0.8.0\n",
      "nbconvert                 7.8.0\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.7\n",
      "networkx                  3.1\n",
      "nlpcloud                  1.1.44\n",
      "notebook                  7.0.3\n",
      "notebook_shim             0.2.3\n",
      "numexpr                   2.8.6\n",
      "numpy                     1.25.2\n",
      "nvidia-cublas-cu11        11.10.3.66\n",
      "nvidia-cuda-cupti-cu11    11.7.101\n",
      "nvidia-cuda-nvrtc-cu11    11.7.99\n",
      "nvidia-cuda-runtime-cu11  11.7.99\n",
      "nvidia-cudnn-cu11         8.5.0.96\n",
      "nvidia-cufft-cu11         10.9.0.58\n",
      "nvidia-curand-cu11        10.2.10.91\n",
      "nvidia-cusolver-cu11      11.4.0.1\n",
      "nvidia-cusparse-cu11      11.7.4.91\n",
      "nvidia-nccl-cu11          2.14.3\n",
      "nvidia-nvtx-cu11          11.7.91\n",
      "openai                    0.28.0\n",
      "openlm                    0.0.5\n",
      "overrides                 7.4.0\n",
      "packaging                 23.1\n",
      "pandas                    2.1.0\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.3\n",
      "peft                      0.5.0\n",
      "pexpect                   4.8.0\n",
      "pickleshare               0.7.5\n",
      "pip                       22.0.2\n",
      "platformdirs              3.10.0\n",
      "prometheus-client         0.17.1\n",
      "prompt-toolkit            3.0.39\n",
      "protobuf                  4.24.3\n",
      "psutil                    5.9.5\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "pyarrow                   13.0.0\n",
      "pycparser                 2.21\n",
      "pydantic                  2.3.0\n",
      "pydantic_core             2.6.3\n",
      "Pygments                  2.16.1\n",
      "python-dateutil           2.8.2\n",
      "python-json-logger        2.0.7\n",
      "python-rapidjson          1.11\n",
      "pytz                      2023.3.post1\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.1\n",
      "qtconsole                 5.4.4\n",
      "QtPy                      2.4.0\n",
      "redis                     5.0.0\n",
      "referencing               0.30.2\n",
      "regex                     2023.8.8\n",
      "requests                  2.31.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      13.4.2\n",
      "rouge                     1.0.1\n",
      "rpds-py                   0.10.3\n",
      "safetensors               0.3.3\n",
      "Send2Trash                1.8.2\n",
      "sentencepiece             0.1.99\n",
      "setuptools                59.6.0\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.0\n",
      "soupsieve                 2.5\n",
      "SQLAlchemy                2.0.20\n",
      "sqlitedict                2.1.0\n",
      "stack-data                0.6.2\n",
      "sympy                     1.12\n",
      "tenacity                  8.2.3\n",
      "terminado                 0.17.1\n",
      "tinycss2                  1.2.1\n",
      "tokenizers                0.13.3\n",
      "tomli                     2.0.1\n",
      "torch                     2.0.1\n",
      "tornado                   6.3.3\n",
      "tqdm                      4.64.1\n",
      "traitlets                 5.10.0\n",
      "transformers              4.33.2\n",
      "triton                    2.0.0\n",
      "tritonclient              2.34.0\n",
      "typing_extensions         4.7.1\n",
      "typing-inspect            0.9.0\n",
      "tzdata                    2023.3\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.0.4\n",
      "wcwidth                   0.2.6\n",
      "webcolors                 1.13\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.6.3\n",
      "wheel                     0.41.2\n",
      "widgetsnbextension        4.0.9\n",
      "xxhash                    3.3.0\n",
      "yarl                      1.9.2\n",
      "zipp                      3.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a314d2-1359-4f07-bf87-02a6b4f886b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65964615fb04437991b6776d4f4801d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peytonwsmith/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8218ffba41fa4265b18bff025c755445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peytonwsmith/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7aed5a20d1425ba60ea1fbd35fc043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peytonwsmith/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024/config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c572d571b6b405c881ef920dd6ae482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peytonwsmith/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024/generation_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4581407a2c4feba255c42013e991c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peytonwsmith/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b28fdf368e448791130acd3494ce5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peytonwsmith/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024/spiece.model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b18c5144c4113bbb84da9a6c59195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/peytonwsmith/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024/tokenizer_config.json\n",
      "/home/peytonwsmith/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "HUGGING_FACE_API_KEY = \"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\"\n",
    "\n",
    "# Replace this if you want to use a different model\n",
    "model_id = \"lmsys/fastchat-t5-3b-v1.0\"\n",
    "filenames = [\n",
    "    \"pytorch_model.bin\", \"added_tokens.json\", \"config.json\", \"generation_config.json\",\n",
    "    \"special_tokens_map.json\", \"spiece.model\", \"tokenizer_config.json\"\n",
    "]\n",
    "\n",
    "for filename in filenames:\n",
    "    downloaded_model_path = hf_hub_download(\n",
    "        repo_id=model_id,\n",
    "        filename=filename,\n",
    "        token=HUGGING_FACE_API_KEY\n",
    "    )\n",
    "\n",
    "    print(downloaded_model_path)\n",
    "\n",
    "print(downloaded_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd04af92-09a4-4093-a539-ffa96e399b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53837d9-2883-4bf3-bb07-2f4401c1d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"lmsys/fastchat-t5-3b-v1.0\"\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id,\n",
    "    task=\"text2text-generation\",\n",
    "    model_kwargs={\"temperature\": 0, \"max_length\": 1000},\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e009ee0f-daa2-45d8-a18c-30daa90787ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a friendly chatbot assistant that responds conversationally to users' questions.\n",
    "Keep the answers short, unless specifically asked by the user to elaborate on something.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f40be1c-e6dc-4110-a10d-8a021c2af6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    result = llm_chain(question)\n",
    "    print(result['question'])\n",
    "    print(\"\")\n",
    "    print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37313283-e90a-4701-8624-624063a2ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class TimerError(Exception):\n",
    "    \"\"\"A custom exception used to report errors in use of Timer class\"\"\"\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        if self._start_time is not None:\n",
    "            raise TimerError(f\"Timer is running. Use .stop() to stop it\")\n",
    "        self._start_time = time.perf_counter()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "        elapsed_time = time.perf_counter() - self._start_time\n",
    "        self._start_time = None\n",
    "        print(f\"Elapsed time: {elapsed_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b64d4a-b114-4d02-aed1-86ba3e02e3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peytonwsmith/llm/env/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "/home/peytonwsmith/llm/env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe some famous landmarks in London\n",
      "\n",
      "<pad> Some  famous  landmarks  in  London  include:\n",
      " *  Buckingham  Palace\n",
      " *  St.  Paul's  Cathedral\n",
      " *  The  Tower  of  London\n",
      " *  The  London  Eye\n",
      " *  The  London  Eye  is  a  giant  wheel  that  flies  over  London.\n",
      "\n",
      "Elapsed time: 2.7787 seconds\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    ask_question(\"Describe some famous landmarks in London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831667b-416a-44ec-bc29-35b6d9abf088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
