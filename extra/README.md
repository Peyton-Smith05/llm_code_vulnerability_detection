# Extra Information

* `llm_tutorial_modified.ipynb` and `llm_tutorial.ipynb` are attempts to download and run codealpaca from HuggingFace. This tutorial came from [here](https://github.com/mneedham/LearnDataWithMark/blob/main/llm-own-laptop/notebooks/LLMOwnLaptop.ipynb).

* `llm_install.ipynb` is code to attempt to install wizard coder llm. 

* `Fine_tune_Llama_2_in_Google_Colab.ipynb` is a tutorial I tried to use to finetune a small LLaMA 2 and query with with my dataset. I was able to get it to work an uploaded it to HuggingFace [here](https://huggingface.co/peytonwsmith/llama2lavafinetune). However, when trying to repull it down and query it, it was missing configuration files and was not loading properly. Tutorial: [Fine-Tune Llama 2 Model on your Custom Data ](https://www.youtube.com/watch?v=Kbk16bqmtO0)

* `quickstart.ipynb` is a modified tutorial from meta to finetune the LLaMA2 model. I also could not get this to work most likely because of the format of the data. If you want to try this again go to [this](https://github.com/facebookresearch/llama-recipes) repository. Clone it and replace this `quickstart.ipynb` file with the `examples/quickstart.ipynb` and it will run. This example loads in the LLaMA models from HuggingFace. 